<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="https://avatars0.githubusercontent.com/u/26362587?s=200&v=4">
  <link rel="stylesheet" href="/assets/bulma.css">
  <link rel="stylesheet" href="/assets/syntax-highlight.css">
  <style>
  #swagger-ui pre.version {
    padding: 2px !important;
    background: initial !important;
  }
  #swagger-ui .topbar {
    display: none;
  }
  blockquote {
    background: #f99;
  }
  aside.menu > ul { 
    position: fixed;
    overflow-y: auto;
    height: calc(100vh - 150px);
  }
  body > #swagger-ui,
  body > .columns {
    margin-top: 55px;
  }
  h2 code, h3 code, h4 code {
    color: black;
  }

  </style><link type="application/atom+xml" rel="alternate" href="https://ocr-d.github.io/feed.xml" title="OCR-D" /></head>
<body><nav class="navbar is-transparent is-fixed-top">

  <div class="navbar-brand">
    <a class="navbar-item" href="/">
      <img src="https://avatars0.githubusercontent.com/u/26362587?s=200&v=4" height="28"/>
    </a>
    <div class="navbar-burger burger" data-target="ocrd-navbar-menu">
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>

  <div id="ocrd-navbar-menu" class="navbar-menu">
    <div class="navbar-start">

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">Specs</a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="/cli">CLI</a>
          <a class="navbar-item" href="/mets">METS</a>
          <a class="navbar-item" href="/page">PAGE</a>
          <a class="navbar-item" href="/ocrd_zip">OCRD-ZIP</a>
          <a class="navbar-item" href="/ocrd_tool">ocrd-tool.json</a>
          <a class="navbar-item" href="/docker">Dockerfile</a>
          <a class="navbar-item" href="/gt">Ground Truth Guidelines</a>
        </div>
      </div>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">Docs</a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="/core">OCR-D/core API</a>
          <a class="navbar-item" href="/slides">Slides / Presentations</a>
          <a class="navbar-item" href="/docs/guide">Guide</a>
          <a class="navbar-item" href="/docs/cookbook">Cookbook</a>
          <a class="navbar-item" href="/docs/faq">FAQ</a>
          <a class="navbar-item" href="/docs/dita">Documenting with DITA</a>
          <a class="navbar-item" href="/docs/vbox">Setting up VirtualBox</a>
        </div>
      </div>

      <a class="navbar-item" href="/glossary">Glossary</a>

    </div>

    <div class="navbar-end">

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">Older versions</a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="/v1.0.0">v1.0.0</a>
          <a class="navbar-item" href="/v1.1.0">v1.1.0</a>
          <a class="navbar-item" href="/v1.1.1">v1.1.1</a>
          <a class="navbar-item" href="/v1.1.2">v1.1.2</a>
          <a class="navbar-item" href="/v1.1.3">v1.1.3</a>
          <a class="navbar-item" href="/v1.1.4">v1.1.4</a>
          <a class="navbar-item" href="/v1.1.5">v1.1.5</a>
          <a class="navbar-item" href="/v1.2.0">v1.2.0</a>
          <a class="navbar-item" href="/v1.3.0">v1.3.0</a>
          <a class="navbar-item" href="/v2.0.0">v2.0.0</a>
          <a class="navbar-item" href="/v2.1.0">v2.1.0</a>
          <a class="navbar-item" href="/v2.1.1">v2.1.1</a>
          <a class="navbar-item" href="/v2.1.2">v2.1.1</a>
          <a class="navbar-item" href="/v2.2.0">v2.2.0</a>
          <a class="navbar-item" href="/v2.2.1">v2.2.1</a>
          <a class="navbar-item" href="/v2.2.2">v2.2.2</a>
          <a class="navbar-item" href="/v2.3.0">v2.3.0</a>
          <a class="navbar-item" href="/v2.3.1">v2.3.1</a>
          <a class="navbar-item" href="/v2.4.0">v2.4.0</a>
          <a class="navbar-item" href="/v2.5.0">v2.5.0</a>
          <a class="navbar-item" href="/v2.6.0">v2.6.0</a>
          <a class="navbar-item" href="/v2.6.1">v2.6.1</a>
          <a class="navbar-item" href="/v2.6.2">v2.6.2</a>
          <a class="navbar-item" href="/v2.7.0">v2.7.0</a>
          <a class="navbar-item" href="/v3.0.0">v3.0.0</a>
          <a class="navbar-item" href="/v3.1.0">v3.1.0</a>
          <a class="navbar-item" href="/">v3.2.0</a>
        </div>
      </div>

      <span class="navbar-item">
        <a href="https://github.com/OCR-D"><img src="https://www.vectorlogo.zone/logos/github/github-tile.svg"/></a>
        &nbsp;
        <a href="https://hub.docker.com/r/ocrd"><img src="https://www.vectorlogo.zone/logos/docker/docker-tile.svg"/></a>
        &nbsp;
        <a href="https://ocr-d.de"><img src="https://www.vectorlogo.zone/logos/fileformatinfo/fileformatinfo-tile.svg"/></a>
      </span>

    </div>
  </div>
</nav>
<div class="columns">
      <aside class="column is-one-third menu">
        <ul class="menu-list column is-one-third">
  <li><a href="#ocr-d-module-projects-mp">OCR-D Module Projects (MP)</a>
    <ul>
      <li><a href="#mp1-scalable-methods-of-text-and-structure-recognition-for-the-full-text-digitization-of-historical-prints-part-1b-image-optimization">[MP1] Scalable Methods of Text and Structure Recognition for the Full-Text Digitization of Historical Prints, Part 1.B: Image Optimization</a></li>
      <li><a href="#mp2-scalable-methods-of-text-and-structure-recognition-for-the-full-text-digitization-of-historical-prints-part-2-layout-analysis">[MP2] Scalable Methods of Text and Structure Recognition for the Full-Text Digitization of Historical Prints, Part 2: Layout Analysis</a></li>
      <li><a href="#mp3-development-of-a-semi-automatic-open-source-tool-for-layout-analysis-and-region-extraction-and-region-classificiation-larex-of-early-prints">[MP3] Development of a semi-automatic open source tool for layout analysis and region extraction and region classificiation (LAREX) of early prints</a></li>
      <li><a href="#mp4-nnfst---unsupervised-ocr-postcorrection-based-on-neural-networks-and-finite-state-transducers">[MP4] NN/FST - Unsupervised OCR-Postcorrection based on Neural Networks and Finite-state Transducers</a></li>
      <li><a href="#mp5-optimized-use-of-ocr-methods--tesseract-as-a-component-of-the-ocr-d-workflow">[MP5] Optimized use of OCR methods – Tesseract as a component of the OCR-D workflow</a></li>
      <li><a href="#mp6-automated-postcorrection-of-ocred-historical-printings-with-integrated-optional-interactive-postcorrection">[MP6] Automated postcorrection of OCRed historical printings with integrated optional interactive postcorrection</a></li>
      <li><a href="#mp7-development-of-a-repository-for-ocr-models-and-an-automatic-font-recognition-tool-in-ocr-d">[MP7] Development of a Repository for OCR Models and an Automatic Font Recognition tool in OCR-D</a></li>
      <li><a href="#mp8-dpo-hp---digital-preservation-of-ocr-d-data-for-historical-printings">[MP8] DPO-HP - Digital Preservation of OCR-D data for historical printings</a></li>
    </ul>
  </li>
</ul>

      </aside>

      <main class="container content column is-two-thirds" aria-label="Content">
        <h1 id="ocr-d-module-projects-mp">OCR-D Module Projects (MP)</h1>

<p>The coordination project <a href="http://ocr-d.de/">OCR-D</a> is developing
<a href="https://ocr-d.github.io/">specifications</a> and a <a href="https://github.com/OCR-D/core">reference
implementation</a> for the development of methods
of Optical Character Recognition (OCR) for printed historical material.</p>

<p>In addition, eight module projects develop prototype implementations for
various workflow steps.</p>

<p>The module project descriptions are taken from the database entries in GEPRIS, the
database of research funded by Deutsche Forschungsgemeinschaft (DFG).</p>

<h2 id="mp1-scalable-methods-of-text-and-structure-recognition-for-the-full-text-digitization-of-historical-prints-part-1b-image-optimization">[MP1] Scalable Methods of Text and Structure Recognition for the Full-Text Digitization of Historical Prints, Part 1.B: Image Optimization</h2>

<p>The project “Skalierbare Verfahren der Text- und Strukturerkennung für die
Volltextdigitalisierung historischer Drucke” has the goal of developing a
complete OCR-Workflow for a high quality mass digitization of historical prints
from the 17th-18th century. For each step in the workflow, innovative methods
should be made available as tools. Module 1.B: Bildoptimierung is the basis on
which high quality OCR provided [sic]. For each optimization, step there are a wide
variety of algorithms available, however not all of them are suitable to the
specific challenges of this projects. On the basis of prior experience and
work, the DFKI plans the identification, development and integration of
suitable methods.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI)</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394343055?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/syedsaqibbukhari/docanalysis</li>
    </ul>
  </li>
</ul>

<h2 id="mp2-scalable-methods-of-text-and-structure-recognition-for-the-full-text-digitization-of-historical-prints-part-2-layout-analysis">[MP2] Scalable Methods of Text and Structure Recognition for the Full-Text Digitization of Historical Prints, Part 2: Layout Analysis</h2>

<p>The project “Skalierbare Verfahren der Text- und Strukturerkennung für die
Volltextdigitalisierung historischer Drucke” has the goal of developing a
complete OCR-Workflow for a high quality mass digitization of historical prints
from the 16th-18th century. For each step in the workflow, innovative methods
should be made available as tools. Module 2: Layouterkennung is next to OCR
itself the most important step. It improves the OCR results directly, but also
improves the general understanding of the digitized document by providing
insights to the layout and relations between the document components. For each
optimization step, there are a wide variety of algorithms available, however not
all of them are suitable to the specific challenges of this projects. On the
basis of prior experience and work, the DFKI plans the identification,
development and integration of suitable methods.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Deutsches Forschungszentrum für Künstliche Intelligenz (DFKI)</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394346204?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/mjenckel/LAYoutERkennung</li>
    </ul>
  </li>
</ul>

<h2 id="mp3-development-of-a-semi-automatic-open-source-tool-for-layout-analysis-and-region-extraction-and-region-classificiation-larex-of-early-prints">[MP3] Development of a semi-automatic open source tool for layout analysis and region extraction and region classificiation (LAREX) of early prints</h2>

<p>The goal of the proposal is the further development of our efficient,
semi-automatic and easy-to-use open-source segmentation tool LAREX und its
integration in the open source workflow of the OCR-D functional model. The
preliminary work LAREX (Layout Analysis and Region EXtraction) allows both a
coarse segmentation by separation of text and non-text and a fine segmentation
by detection and classification of different textual entites. LAREX utilizes an
efficient implementation of the connected component approach. It has been used
in the digitalization of different early prints und enables a qualitative good
page segmentation with significantly less time than conventional alternatives.
The main goal of the further development of LAREX is to reduce the degree of
manual work. Therefore, a more robust segmentation und a further development of
the rule and constraint language are necessary. The basic configurations should
be easily adaptable to the peculiarities of a particular early print by both
the users and learning algorithms. Furthermore, the comfortable GUI of LAREX
for correction of single segmentation errors should be improved. This component
is also necessary for defining a ground truth for learning algorithms and for
evaluation. The overall goal is to find an optimal combination between manual
and automatic methods. The tool and the process model will be substantially
evaluated with various cooperation partners, in particular in the context of
the digitalization of early prints within the OCR-D function model including
the subsequent OCR by the linkage of external tools.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Julius-Maximilians-Universität Würzburg, Institut für Informatik: Lehrstuhl für Künstliche Intelligenz und angewandte Informatik</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394329162?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/ocr-d-modul-2-segmentierung/segmentation-runner</li>
      <li>https://github.com/ocr-d-modul-2-segmentierung/page-segmentation</li>
    </ul>
  </li>
</ul>

<h2 id="mp4-nnfst---unsupervised-ocr-postcorrection-based-on-neural-networks-and-finite-state-transducers">[MP4] NN/FST - Unsupervised OCR-Postcorrection based on Neural Networks and Finite-state Transducers</h2>

<p>The project aims to develop a ready to use software für modul 3 (text
optimization) of the OCR-D architecture. The focus of development is in area
3.B (postcorrection) where we plan to also evaluate some up-to-date OCR systems
(area 3.A). The main technologies that we plan to use are neural nets (NN)
combined with finite-state transducers (FST) to decode recognized lines of text
within a noisy-channel model.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Universität Leipzig, Institut für Informatik: Abteilung Automatische Sprachverarbeitung</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394341797?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/ocr-d-modul-2-segmentierung/segmentation-runner</li>
    </ul>
  </li>
</ul>

<h2 id="mp5-optimized-use-of-ocr-methods--tesseract-as-a-component-of-the-ocr-d-workflow">[MP5] Optimized use of OCR methods – Tesseract as a component of the OCR-D workflow</h2>

<p>Tesseract is a free software for text recognition (optical character
recognition, OCR). This software has a history of more than 30 years of
continuous development and improvements. In the small group of open source
products for OCR Tesseract belongs to the programs with the best recognition
rates. Since end of 2016 Tesseract supports state-of-the-art text recognition by
neural networks (LSTM). The context of OCR-D requires well defined interfaces
for OCR software. The project will actively contribute to the definition of
such interfaces. It will implement them for Tesseract to allow inclusion of
Tesseract in an OCR workflow. We also strive to improve the stability,
performance and practical usability of Tesseract.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Universität Mannheim, Universitätsbibliothek Mannheim</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394264782?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/OCR-D/ocrd_tesserocr</li>
    </ul>
  </li>
</ul>

<h2 id="mp6-automated-postcorrection-of-ocred-historical-printings-with-integrated-optional-interactive-postcorrection">[MP6] Automated postcorrection of OCRed historical printings with integrated optional interactive postcorrection</h2>

<p>The obvious need to improve current methods for full-text digitalization of
historical printings represents the general background of the DFG-program
“Skalierbare Verfahren der Text- und Strukturerkennung für die
Volltextdigitalisierung historischer Drucke”. Module 3 of this program in
particular explains the need for high-level postcorrection of the OCR output.
In our team we developed over several years a specialized system “PoCoTo” for
the interactive postcorrection of OCRed historical printings. Still, in the
context of mass digitization for obvious reasons systems for automated
postcorrection are clearly preferable. The main problem for automated
postcorrection is to avoid a replacement of correct OCR-tokens that are not
covered by the background correction dictionary. Building up on PoCoTo we want
to develop an advanced system for automated postcorrection that largely avoids
such ‘infelicitous correction steps. To this end, the PoCoTo background
technology will be substantially extended. Since a fully automated
postcorrection will not always reach the very high quality standards needed,
the automated correction can be completed by an optional semi-automated or
interactive postcorrection. Methods for semi-automated or interactive
postcorrection that take advantage of all data and insights from the automated
correction phase will be directly integrated as part of the system.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Ludwig-Maximilians-Universität München, Centrum für Informations- und Sprachverarbeitung (CIS)</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/393215159?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/cisocrgroup/ocrd-postcorrection</li>
    </ul>
  </li>
</ul>

<h2 id="mp7-development-of-a-repository-for-ocr-models-and-an-automatic-font-recognition-tool-in-ocr-d">[MP7] Development of a Repository for OCR Models and an Automatic Font Recognition tool in OCR-D</h2>

<p>The project addresses the problem of strongly fluctuating recognition rates of
OCR for 16th to 18th century historical prints, limiting the full-text
digitization of material created by the VD16, VD17, and VD18
programs. Recognition models trained on modern corpora lacking the specifics of
historical prints or historic material without thorough bibliographic analysis,
retard recognition rates in comparison to the accuracy now routinely achieved
for scans of modern prints. The creation of font-specific corpora on the basis
of manual tagging is unrealistic, since both non-trivial knowledge of printing
history is necessary and the scalability of such an approach would be
insufficient. Due to the repetitiveness of the task, such an approach is also
very error-prone. The project will enable the humanities to use OCR in a
font-specific manner with limited effort. In order to achieve this the project
has three main objectives: The development of an online training infrastructure
that allows specific models to be trained for these font groups and at the same
time for different OCR software. Development of a tool for the automatic
recognition of fonts in digitizations of historical prints. In this case, an
algorithm for the recognition of fonts in incunabula is first trained using the
ground truth found in the Typenrepertorium der Wiegendrucke. In a second step
the fonts are grouped according to their similarity in order to get as few
groups as possible while maintaining OCR accuracy. Provision of a model
repository, in which developed font-specific OCR models are made available to
the public.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Universität Leipzig,   Institut für Informatik: Lehrstuhl für Digital Humanities</li>
      <li>Friedrich-Alexander-Universität Erlangen-Nürnberg, Department Informatik: Lehrstuhl für Informatik 5: Mustererkennung</li>
      <li>Johannes Gutenberg-Universität Mainz, Gutenberg-Institut für Weltliteratur und schriftorientierte Medien: Abteilung Buchwissenschaft</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394448308?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/seuretm/ocrd_typegroups_classifier</li>
      <li>https://github.com/Doreenruirui/okralact</li>
    </ul>
  </li>
</ul>

<h2 id="mp8-dpo-hp---digital-preservation-of-ocr-d-data-for-historical-printings">[MP8] DPO-HP - Digital Preservation of OCR-D data for historical printings</h2>

<p>In order to provide high-quality and comprehensive research in the field of
historical sciences, unrestricted access to historical sources is mandatory.
Numerous images of historical prints from the 16th to the 19th century are now
available by means of several cataloging and digitization projects. Not only
the serial cataloging, but also the mass digitization of titles has been
improved especially in the context of the “Verzeichnisse Deutscher Drucke”. The
processed works have been cataloged not only according to national
bibliographic standards, but have also been digitized to a large extent. The
bibliographic metadata standard of these images already meets the scientific
requirements. For further research, it is crucial to be able to specifically
search and use the full texts of digitized works as well. The techniques of
Optical Character Recognition (OCR) allow the mass creation of full texts. For
an immediate usage in libraries, archives and other institutions, however, the
methods used so far were not suitable, since the texts show too many
orthographic differences. There has been intensive work on easily transferable
applications that allow a high-quality mass-processing of all historical prints
from the 16th to the 19th century. This will increase the number of OCR texts
rapidly. For further usage, a sustainable preservation and identification of the
images, the bibliographic metadata as well as the encoded full texts and their
versions is obligatory. A standardized concept must be created in order to
ensure this purpose. In addition, the availability and citation of the OCR
texts is an important prerequisite for the verifiability of scientific results.
Hence OCR texts must be added to the existing archive of a digital object along
with its structure and metadata and images. Different versions of the same
starting material are created through intellectual efforts, improvements
especially in the OCR process or the usage of various OCR techniques, which
bear a new challenge for persistent identification and long-term preservation.
This problem contains aspects related to research data management and also
requires the consideration of methods and strategies for dealing with research
data. The above requirements must be conceptually prepared, integrated into an
extended context, and implemented as a technical solution in order to meet the
requirements of the data holders as well as the users. Based on this initial
situation, this project defines the necessary steps for the realization of a
solution for long-term preservation and persistent identification of OCR texts.</p>

<ul>
  <li>Partner(s):
    <ul>
      <li>Georg-August-Universität Göttingen, Niedersächsische Staats- und Universitätsbibliothek</li>
      <li>Gesellschaft für Wissenschaftliche Datenverarbeitung mbH Göttingen</li>
    </ul>
  </li>
  <li>URL:
    <ul>
      <li>GEPRIS: http://gepris.dfg.de/gepris/projekt/394410994?language=en</li>
    </ul>
  </li>
  <li>GitHub:
    <ul>
      <li>https://github.com/subugoe/OLA-HD-IMPL</li>
    </ul>
  </li>
</ul>

      </main>
    </div><footer class="level">

  <div class="level-item">
    <p>
<!-- BEGIN-EVAL echo "Based on <a href="https://github.com/OCR-D/spec/releases/tag/${SPEC_VERSION:-dev}">OCR-D/spec ${SPEC_VERSION:-dev}</a>." -->
Based on <a href=https://github.com/OCR-D/spec/releases/tag/v3.2.0>OCR-D/spec v3.2.0</a>.

<!-- END-EVAL -->
    </p>
    &nbsp;


<!-- BEGIN-EVAL echo "<p>Generated on <code>$(date)</code></p>" -->
<p>Generated on <code>Wed Feb 27 15:53:08 CET 2019</code></p>

<!-- END-EVAL -->
  </div>

</footer>
<script src="/assets/script.js"></script>
</body>

</html>
